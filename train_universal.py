"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MÃ³dulo: train_universal.py
Proyecto: Arquitectura Minera 4.0
Autor: Juan Galaz (Refactorizado por Gemini)
VersiÃ³n: 2.3.1 - AUDIT-READY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DESCRIPCIÃ“N:
    Orquestador de alto nivel para el entrenamiento de Soft-Sensors. 
    Implementa un pipeline de MLOps que automatiza la ingesta filtrada, 
    la optimizaciÃ³n bayesiana de parÃ¡metros y la generaciÃ³n de reportes forenses.

FASE 1: Ingesta con MiningDataAdapter (DetecciÃ³n y Limpieza).
FASE 2: Modelado con MiningGP (OptimizaciÃ³n Optuna y Gaussian Process).
FASE 3: Reporting (MÃ©tricas de precisiÃ³n y persistencia .pkl).

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import sys
import logging
from pathlib import Path
from datetime import datetime

# Interfaz y UI
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

# MÃ³dulos del Proyecto
sys.path.insert(0, str(Path(__file__).parent.parent))
from core.adapters import MiningDataAdapter
from core.models.mining_gp_pro import MiningGP, ModelMetrics
from config.settings import CONFIG

# ConfiguraciÃ³n de Logging Industrial
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Trainer_v2.3.1")
console = Console()

def prepare_data_phase() -> tuple:
    """
    FASE 1: Ingesta y PreparaciÃ³n.
    Utiliza el MiningDataAdapter para sanitizar el CSV y aplicar los filtros
    definidos en el esquema JSON.
    
    Returns:
        tuple: (ruta_archivo_filtrado, configuracion_dict, instancia_adapter)
    """
    console.print(Panel("ğŸ“¥ [bold cyan]FASE 1: INGESTA Y FILTRADO UNIFICADO[/bold cyan]", border_style="cyan"))
    
    adapter = MiningDataAdapter("dataset_config.json")
    df = adapter.load_data() # Hace el trabajo pesado de limpieza
    
    # Crear archivo temporal para el entrenamiento
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    temp_path = CONFIG.DATA_PROCESSED_DIR / f"train_input_{timestamp}.csv"
    df.to_csv(temp_path)
    
    logger.info(f"âœ… Datos preparados: {len(df)} registros listos para el modelo.")
    return temp_path, adapter.config, adapter

def train_model_phase(data_path: Path, ad_config: dict) -> tuple:
    """
    FASE 2: Entrenamiento Predictivo.
    Instancia el modelo MiningGP y ejecuta la optimizaciÃ³n de hiperparÃ¡metros.
    
    Args:
        data_path: Ruta al CSV preparado en la Fase 1.
        ad_config: ConfiguraciÃ³n extraÃ­da del adaptador.
        
    Returns:
        tuple: (modelo_entrenado, objeto_metricas)
    """
    console.print(Panel("ğŸ§  [bold yellow]FASE 2: ENTRENAMIENTO Y OPTIMIZACIÃ“N (GP)[/bold yellow]", border_style="yellow"))
    
    target = ad_config["modeling"]["target_column"]
    
    # Instanciamos el modelo v4.1 (Gaussian Process)
    model = MiningGP(
        target_col=target,
        use_fallback_model=True # Si el R2 es muy bajo, usa Gradient Boosting
    )
    
    # EjecuciÃ³n del entrenamiento con trials dinÃ¡micos desde CONFIG
    metrics = model.train_from_file(
        filepath=str(data_path),
        n_trials=CONFIG.GP_OPTUNA_TRIALS, # CORRECCIÃ“N AUDITORÃA: Ya no estÃ¡ hardcodeado
        save_model=True
    )
    
    return model, metrics

def report_phase(dataset_name: str, model: MiningGP, metrics: ModelMetrics):
    """
    FASE 3: AuditorÃ­a y Cierre.
    Genera un resumen ejecutivo en consola sobre la calidad del Soft-Sensor.
    """
    console.print(Panel("ğŸ“Š [bold green]FASE 3: RESUMEN EJECUTIVO DE CALIDAD[/bold green]", border_style="green"))
    
    table = Table(show_header=True, header_style="bold magenta")
    table.add_column("MÃ©trica", style="dim")
    table.add_column("Valor")
    table.add_column("EvaluaciÃ³n")

    # EvaluaciÃ³n visual del R2
    r2 = metrics.r2
    status = "[bold green]ğŸ† Excelente[/]" if r2 > 0.8 else "[yellow]ğŸ‘ Aceptable[/]" if r2 > 0.5 else "[red]âš ï¸ Pobre[/]"
    
    table.add_row("RÂ² Score (PrecisiÃ³n)", f"{r2:.4f}", status)
    table.add_row("MAPE (Error %)", f"{metrics.mape:.2f}%", "âœ…" if metrics.mape < 10 else "â—")
    table.add_row("Algoritmo Final", model.model_type, "ğŸ§ " if model.model_type == "GP" else "ğŸŒ²")
    
    console.print(table)
    console.print(f"\n[dim]Modelo guardado en: {CONFIG.MODELS_DIR}[/dim]")

def main():
    """Punto de entrada principal del Pipeline."""
    try:
        console.print(Panel.fit("ğŸš€ [bold blue]PIPELINE UNIVERSAL v2.3.1[/bold blue]\n[italic]Mining Architecture 4.0[/italic]"))
        
        # Log de parÃ¡metros activos
        console.print(f"[dim]âš™ï¸ Config: Trials={CONFIG.GP_OPTUNA_TRIALS} | Subsample={CONFIG.DEFAULT_SUBSAMPLE_STEP}[/dim]\n")

        # EjecuciÃ³n de las 3 fases
        data_path, config, adapter = prepare_data_phase()
        model, metrics = train_model_phase(data_path, config)
        report_phase(config.get('dataset_name', 'Mining_Dataset'), model, metrics)

    except Exception as e:
        console.print(f"\n[bold red]ğŸ”¥ ERROR CRÃTICO:[/bold red] {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
