"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Script: train_universal.py
Proyecto: Arquitectura Minera 4.0
Autor: Juan Galaz
VersiÃ³n: 2.2.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DESCRIPCIÃ“N:
    Orquestador Universal del Pipeline de Entrenamiento (MLOps).
    
    Este script es el "Director de Orquesta" que conecta:
    1. INGESTA: UniversalAdapter (Carga inteligente basada en JSON)
    2. MODELADO: MiningGP v4.1 (Gaussian Process con correcciÃ³n de ruido)
    3. PERSISTENCIA: Guardado automÃ¡tico de modelos y mÃ©tricas.

    El flujo completo es:
    
        CSV â†’ UniversalAdapter â†’ MiningGP â†’ Modelo.pkl + Reporte.png
        
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HISTORIAL DE CAMBIOS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    [v2.2.0 - Enero 2026] CLEAN CODE UPDATE
    ----------------------------------------
    
    âœ… FIX: Subsample centralizado en CONFIG
    
       ANTES:
           # LÃ­nea ~95 (hardcodeado)
           subsample_step = 10  # âŒ Valor "mÃ¡gico" suelto en el cÃ³digo
       
       AHORA:
           # Importamos desde config/settings.py
           from config.settings import CONFIG
           
           # Y usamos el valor centralizado
           # (MiningGP ya lo usa por defecto, no necesitamos pasarlo explÃ­citamente)
       
       RAZÃ“N:
           Antes, si querÃ­as cambiar el subsample tenÃ­as que editar:
           - train_universal.py (valor 10)
           - inference.py (valor 50)  
           - mining_gp_pro.py (valor 50)
           
           Ahora solo editas config/settings.py y todo el sistema cambia.
    
    âœ… LIMPIEZA: Eliminado cÃ³digo redundante
       - Ya no pasamos subsample_step explÃ­cito a MiningGP
       - MiningGP usa CONFIG.DEFAULT_SUBSAMPLE_STEP por defecto

    [v2.1.0] IntegraciÃ³n con UniversalAdapter
    [v2.0.0] MigraciÃ³n a MiningGP
    [v1.0.0] VersiÃ³n inicial

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USO:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # Desde lÃ­nea de comandos (modo estÃ¡ndar)
    python train_universal.py
    
    # El script lee la configuraciÃ³n desde:
    # - config/dataset_config.json  (reglas del dataset)
    # - config/settings.py          (parÃ¡metros globales)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTACIONES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import logging
import sys
from pathlib import Path
from datetime import datetime

# Rich - Interfaz de usuario profesional
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

# MÃ³dulos internos de la Arquitectura Minera
from core.adapters.universal_adapter import UniversalAdapter
from core.models.mining_gp_pro import MiningGP, ModelMetrics
from config.settings import CONFIG  # â† [v2.2.0] Importamos la configuraciÃ³n centralizada

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N DE LOGGING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger("Universal_Trainer_v2.2")
console = Console()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 1: INGESTA Y PREPARACIÃ“N DE DATOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def prepare_data_with_adapter(config_filename: str = "dataset_config.json") -> tuple:
    """
    Carga y limpia datos usando UniversalAdapter.
    
    El UniversalAdapter actÃºa como un "firewall de datos":
    - Lee reglas desde un archivo JSON
    - Filtra columnas segÃºn patrones (include/exclude)
    - Elimina columnas que causan data leakage
    - Aplica forward-fill para valores nulos
    
    Args:
        config_filename: Nombre del archivo de configuraciÃ³n JSON
                        (debe estar en config/)
    
    Returns:
        Tuple de (ruta_csv_temporal, configuraciÃ³n_dict)
        
    Raises:
        FileNotFoundError: Si no encuentra el JSON o el CSV
        KeyError: Si el JSON estÃ¡ mal formado
    """
    console.print(Panel.fit(
        "ğŸ“¥ FASE 1: Carga y Filtrado de Datos", 
        style="bold cyan"
    ))
    
    try:
        # Inicializar adaptador (lee el JSON automÃ¡ticamente)
        adapter = UniversalAdapter(config_filename)
        logger.info(f"ğŸ“‹ Dataset configurado: {adapter.config['dataset_name']}")
        
        # Cargar y filtrar datos segÃºn reglas del JSON
        df = adapter.load_data()
        
        # Mostrar estadÃ­sticas de carga
        console.print(f"\n[bold green]âœ… Datos cargados y filtrados exitosamente:[/bold green]")
        
        stats_table = Table(show_header=False, box=None, padding=(0, 2))
        stats_table.add_row("Registros:", f"{len(df):,}")
        stats_table.add_row("Features:", f"{len(df.columns) - 1}")  # -1 por el target
        stats_table.add_row("Target:", adapter.config["modeling"]["target_column"])
        stats_table.add_row("Rango temporal:", f"{df.index.min()} â†’ {df.index.max()}")
        console.print(stats_table)
        
        # Guardar CSV temporal para que MiningGP lo lea
        # (MiningGP espera un archivo, no un DataFrame directamente)
        CONFIG.DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        dataset_name = adapter.config['dataset_name']
        temp_filepath = CONFIG.DATA_PROCESSED_DIR / f"{dataset_name}_filtered_{timestamp}.csv"
        
        df.to_csv(temp_filepath)
        logger.info(f"ğŸ’¾ CSV temporal guardado: {temp_filepath}")
        
        return temp_filepath, adapter.config
        
    except FileNotFoundError as e:
        logger.critical(f"âŒ Archivo no encontrado: {e}")
        raise
    except KeyError as e:
        logger.critical(f"âŒ JSON mal formado - falta clave: {e}")
        raise
    except Exception as e:
        logger.critical(f"ğŸ’¥ Error fatal en ingesta: {e}")
        raise


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 2: ENTRENAMIENTO (CORE ML)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def train_model_with_gp(
    data_filepath: Path,
    adapter_config: dict,
    n_trials: int = 50
) -> tuple:
    """
    Ejecuta el entrenamiento del Soft-Sensor usando MiningGP v4.1.
    
    Esta funciÃ³n es el corazÃ³n del pipeline. Conecta los datos preparados
    con el modelo de Gaussian Process y maneja todo el ciclo de vida:
    - DiagnÃ³stico de autocorrelaciÃ³n
    - OptimizaciÃ³n de hiperparÃ¡metros (Optuna)
    - Entrenamiento final
    - EvaluaciÃ³n y generaciÃ³n de reportes
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [v2.2.0] NOTA IMPORTANTE SOBRE SUBSAMPLE:
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ANTES (v2.1.0 y anteriores):
        # El valor estaba hardcodeado aquÃ­
        model = MiningGP(
            target_col=target_col,
            subsample_step=10,  # âŒ Hardcode - fÃ¡cil de olvidar actualizar
            ...
        )
    
    AHORA (v2.2.0):
        # MiningGP usa CONFIG.DEFAULT_SUBSAMPLE_STEP por defecto
        # No necesitamos pasar el valor explÃ­citamente
        model = MiningGP(
            target_col=target_col,
            # subsample_step usa CONFIG automÃ¡ticamente âœ…
            ...
        )
    
    Si necesitas un subsample diferente para este entrenamiento especÃ­fico,
    puedes pasarlo explÃ­citamente:
        model = MiningGP(target_col=target_col, subsample_step=20)
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Args:
        data_filepath: Ruta al CSV filtrado (output de Fase 1)
        adapter_config: Diccionario con configuraciÃ³n del dataset
        n_trials: NÃºmero de trials para optimizaciÃ³n Optuna
        
    Returns:
        Tuple de (modelo_entrenado, mÃ©tricas)
    """
    console.print(Panel.fit(
        "ğŸ§  FASE 2: Entrenamiento con MiningGP v4.1", 
        style="bold yellow"
    ))
    
    try:
        # Extraer columna objetivo del config
        target_col = adapter_config["modeling"]["target_column"]
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [v2.2.0] CREACIÃ“N DEL MODELO
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ya NO pasamos subsample_step explÃ­citamente.
        # MiningGP lo toma de CONFIG.DEFAULT_SUBSAMPLE_STEP por defecto.
        #
        # Esto garantiza que entrenamiento e inferencia usen el mismo valor,
        # evitando el bug de desalineaciÃ³n de features que tenÃ­amos antes.
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        model = MiningGP(
            target_col=target_col,
            # subsample_step: usa CONFIG.DEFAULT_SUBSAMPLE_STEP (actualmente 10)
            add_lag_features=True,           # Agregar Y(t-1), Y(t-5), etc.
            add_diff_features=True,          # Agregar diferencias y rolling stats
            use_fallback_model=True,         # Usar GradientBoosting si GP falla
            remove_constant_features=True,   # Eliminar features con std â‰ˆ 0
            remove_correlated_features=True  # Eliminar features redundantes
        )
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Log de configuraciÃ³n
        logger.info(f"ğŸ¯ Target columna: {target_col}")
        logger.info(
            f"ğŸ”§ ConfiguraciÃ³n: "
            f"Optuna Trials={n_trials} | "
            f"Subsample=1/{CONFIG.DEFAULT_SUBSAMPLE_STEP} (desde CONFIG)"
        )
        
        # Ejecutar pipeline completo de entrenamiento
        metrics = model.train_from_file(
            filepath=str(data_filepath),
            test_size=0.2,      # 80% train, 20% test
            n_trials=n_trials,  # NÃºmero de experimentos Optuna
            save_model=True     # Guardar .pkl automÃ¡ticamente
        )
        
        return model, metrics
        
    except ValueError as e:
        logger.critical(f"âŒ Error de validaciÃ³n de datos: {e}")
        raise
    except Exception as e:
        logger.critical(f"ğŸ’¥ Error durante el entrenamiento: {e}")
        raise


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 3: REPORTING Y CIERRE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_summary_report(
    dataset_name: str,
    model: MiningGP,
    metrics: ModelMetrics,
    data_filepath: Path
) -> None:
    """
    Genera el reporte final de calidad del modelo.
    
    Muestra un resumen ejecutivo con:
    - Dataset utilizado
    - Tipo de modelo final (GP o GradientBoosting)
    - MÃ©tricas clave con interpretaciÃ³n
    - Rutas de archivos generados
    
    Args:
        dataset_name: Nombre del dataset procesado
        model: Instancia del modelo entrenado
        metrics: MÃ©tricas de evaluaciÃ³n
        data_filepath: Ruta al CSV usado para entrenamiento
    """
    console.print(Panel.fit("ğŸ“Š RESUMEN EJECUTIVO", style="bold green"))
    
    # Tabla de auditorÃ­a
    summary = Table(
        title="AuditorÃ­a del Modelo Entrenado", 
        show_header=True, 
        header_style="bold cyan"
    )
    summary.add_column("KPI", style="dim")
    summary.add_column("Resultado", style="white")
    summary.add_column("Estado", style="white")
    
    # Fila 1: Dataset
    summary.add_row("Dataset", dataset_name, "âœ…")
    
    # Fila 2: Tipo de modelo
    model_emoji = "ğŸ§ " if model.model_type == "GP" else "ğŸŒ²"
    summary.add_row("Modelo Final", f"{model_emoji} {model.model_type}", "âœ…")
    
    # Fila 3: Features
    summary.add_row("Features Activos", str(len(model.feature_names)), "âœ…")
    
    # Fila 4: RÂ² con color segÃºn calidad
    r2_val = metrics.r2
    if r2_val > 0.7:
        r2_display = f"[bold green]{r2_val:.4f}[/bold green]"
        r2_status = "ğŸ† Excelente"
    elif r2_val > 0.5:
        r2_display = f"[yellow]{r2_val:.4f}[/yellow]"
        r2_status = "ğŸ‘ Aceptable"
    else:
        r2_display = f"[red]{r2_val:.4f}[/red]"
        r2_status = "âš ï¸ Revisar"
    summary.add_row("RÂ² Score", r2_display, r2_status)
    
    # Fila 5: RMSE
    summary.add_row("RMSE", f"{metrics.rmse:.4f}", "-")
    
    # Fila 6: MAPE
    mape_status = "âœ…" if metrics.mape < 10 else "âš ï¸"
    summary.add_row("MAPE", f"{metrics.mape:.2f}%", mape_status)
    
    console.print(summary)
    
    # Mensaje final segÃºn resultado
    if r2_val < 0:
        console.print("\n[bold red]â›” FALLO: El modelo no es predictivo (RÂ² negativo).[/bold red]")
        console.print("[dim]   Posibles causas: datos insuficientes, target muy ruidoso, data leakage.[/dim]")
    elif r2_val > 0.7:
        console.print("\n[bold green]ğŸ† Ã‰XITO: Modelo de alta precisiÃ³n listo para despliegue.[/bold green]")
    else:
        console.print("\n[yellow]âš ï¸ PRECAUCIÃ“N: Modelo funcional pero con margen de mejora.[/yellow]")
        console.print("[dim]   Sugerencia: Revisar features, probar mÃ¡s trials de Optuna.[/dim]")
    
    # Mostrar rutas de archivos generados
    console.print(f"\n[dim]ğŸ“ Archivos generados:[/dim]")
    console.print(f"[dim]   â€¢ Modelo: {CONFIG.MODELS_DIR}/*.pkl[/dim]")
    console.print(f"[dim]   â€¢ Reporte: {CONFIG.RESULTS_DIR}/*.png[/dim]")
    console.print(f"[dim]   â€¢ Datos: {data_filepath}[/dim]")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N PRINCIPAL (MAIN)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """
    FunciÃ³n principal del pipeline de entrenamiento.
    
    Orquesta las 3 fases:
    1. Ingesta de datos (UniversalAdapter)
    2. Entrenamiento del modelo (MiningGP)
    3. GeneraciÃ³n de reportes
    
    Exit codes:
        0: Ã‰xito (RÂ² > 0)
        1: Fallo (RÂ² â‰¤ 0 o error)
        130: Interrumpido por usuario (Ctrl+C)
    """
    try:
        # Banner de inicio
        console.print(Panel.fit(
            "ğŸš€ Pipeline Universal de Entrenamiento v2.2.0\n"
            "Clean Code Update - Enero 2026\n"
            "Arquitectura Minera 4.0",
            style="bold blue"
        ))
        
        # Mostrar configuraciÃ³n actual
        console.print(f"[dim]ğŸ“‹ ConfiguraciÃ³n activa:[/dim]")
        console.print(f"[dim]   â€¢ DEFAULT_SUBSAMPLE_STEP = {CONFIG.DEFAULT_SUBSAMPLE_STEP}[/dim]")
        console.print(f"[dim]   â€¢ GP_TARGET = {CONFIG.GP_TARGET_COLUMN}[/dim]")
        console.print(f"[dim]   â€¢ GP_TRIALS = {CONFIG.GP_OPTUNA_TRIALS}[/dim]")
        console.print()
        
        # === PASO 1: INGESTA DE DATOS ===
        data_filepath, adapter_config = prepare_data_with_adapter()
        
        # === PASO 2: ENTRENAMIENTO DEL MODELO ===
        model, metrics = train_model_with_gp(
            data_filepath=data_filepath,
            adapter_config=adapter_config,
            n_trials=50  # Puedes ajustar esto
        )
        
        # === PASO 3: REPORTE FINAL ===
        generate_summary_report(
            dataset_name=adapter_config['dataset_name'],
            model=model,
            metrics=metrics,
            data_filepath=data_filepath
        )
        
        # Determinar exit code
        exit_code = 0 if metrics.r2 > 0 else 1
        logger.info(f"âœ… Pipeline finalizado. Exit Code: {exit_code}")
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        console.print("\n[yellow]âš ï¸ Proceso interrumpido por usuario (Ctrl+C).[/yellow]")
        sys.exit(130)
        
    except Exception as e:
        console.print(f"\n[bold red]ğŸ”¥ ERROR FATAL: {e}[/bold red]")
        import traceback
        traceback.print_exc()
        sys.exit(1)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PUNTO DE ENTRADA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    main()
