"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
M√≥dulo: core/inference_engine.py
Autor: Juan Galaz (Arquitectura Minera 4.0)
Versi√≥n: 1.1 (Documentaci√≥n Extendida)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

DESCRIPCI√ìN:
    Motor de Inferencia dedicado para Producci√≥n.
    
    Este m√≥dulo act√∫a como una 'Fachada' (Facade Pattern) que abstrae la 
    complejidad de cargar modelos, generar features en tiempo real y 
    desescalar predicciones.

    RESPONSABILIDADES:
    1. Gesti√≥n de Artefactos: Carga autom√°tica del modelo m√°s reciente (.pkl).
    2. Feature Engineering On-the-Fly: Recrea los lags y diffs necesarios
       para que el modelo entienda el contexto temporal.
    3. Seguridad: Valida que los datos de entrada coincidan con los del entrenamiento.

USO:
    engine = MiningInference()
    resultado = engine.predict_scenario(df_ultimas_50_horas)
"""

import logging
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Optional, Tuple

# Importaciones internas
from config.settings import CONFIG
from core.models.mining_gp_pro import MiningGP, TrainingArtifacts

# Configuraci√≥n de logger local
logger = logging.getLogger("InferenceEngine")

class MiningInference:
    """
    Clase controladora para la ejecuci√≥n de modelos mineros en producci√≥n.
    """

    def __init__(self, model_path: Optional[str] = None):
        """
        Inicializa el motor de inferencia.

        L√≥gica de Carga:
        - Si se provee 'model_path', carga ese archivo espec√≠fico.
        - Si NO se provee, busca autom√°ticamente el .pkl m√°s nuevo en 'models/'.

        Args:
            model_path (str, optional): Ruta absoluta al archivo .pkl. 
                                        Por defecto es None.
        """
        # Instancia vac√≠a de MiningGP para acceder a sus m√©todos de utilidad
        # (como _create_lag_features) sin necesidad de re-implementarlos.
        self.model_wrapper = MiningGP() 
        self.loaded = False
        self.model_path = None
        
        # Estrategia de carga autom√°tica
        if model_path:
            self.load_model(Path(model_path))
        else:
            self._load_latest_model()

    def _load_latest_model(self) -> None:
        """
        Escanea el directorio de modelos y carga el archivo modificado m√°s recientemente.
        
        Raises:
            FileNotFoundError: Si la carpeta 'models/' est√° vac√≠a.
        """
        try:
            # Glob pattern para encontrar todos los pickles
            models = list(CONFIG.MODELS_DIR.glob("*.pkl"))
            
            if not models:
                msg = f"‚ùå No se encontraron modelos entrenados en: {CONFIG.MODELS_DIR}"
                logger.error(msg)
                raise FileNotFoundError(msg)
            
            # Ordenar por fecha de modificaci√≥n (st_mtime) descendente
            latest_model = max(models, key=lambda p: p.stat().st_mtime)
            logger.info(f"üîé Modelo m√°s reciente detectado: {latest_model.name}")
            
            self.load_model(latest_model)
            
        except Exception as e:
            logger.critical(f"üí• Error cr√≠tico buscando modelo: {e}")
            raise

    def load_model(self, path: Path) -> None:
        """
        Deserializa y carga los artefactos del modelo en memoria.

        Args:
            path (Path): Objeto Path apuntando al archivo .pkl.

        Raises:
            Exception: Si el archivo est√° corrupto o es de una versi√≥n incompatible.
        """
        logger.info(f"üìÇ Cargando artefactos desde disco...")
        try:
            # Usamos el m√©todo nativo .load() de la clase MiningGP
            # Esto restaura: modelo, scalers, nombres de columnas y configuraci√≥n.
            self.model_wrapper.load(str(path))
            
            self.model_path = path
            self.loaded = True
            logger.info(f"‚úÖ Inferencia lista. Modelo activo: {self.model_wrapper.model_type}")
            
        except Exception as e:
            logger.critical(f"‚ùå Error al cargar el modelo (¬øArchivo corrupto?): {e}")
            raise

    def predict_scenario(self, df_recent_history: pd.DataFrame) -> Dict:
        """
        Ejecuta una predicci√≥n para el estado actual del proceso.

        IMPORTANTE - TEOR√çA DE SERIES DE TIEMPO:
        Un modelo temporal no puede predecir con una sola fila de datos (t).
        Necesita el contexto hist√≥rico (t-1, t-5, etc.) para calcular
        lags y promedios m√≥viles.
        
        Por eso, este m√©todo requiere un DataFrame con historia reciente,
        aunque solo devuelva la predicci√≥n para el √∫ltimo instante.

        Args:
            df_recent_history (pd.DataFrame): DataFrame con las √∫ltimas N filas
                                              (ej. 50 registros) de los sensores.

        Returns:
            Dict: Diccionario con la predicci√≥n, valor real (si existe) y metadatos.
                  Estructura: {
                      "timestamp": str,
                      "predicted_value": float,
                      "real_value": float | None,
                      "model_used": str,
                      "confidence_std": float
                  }

        Raises:
            RuntimeError: Si el modelo no ha sido cargado previamente.
        """
        if not self.loaded:
            raise RuntimeError("‚ö†Ô∏è Intento de predicci√≥n sin modelo cargado.")

        try:
            target_col = self.model_wrapper.target_col
            
            # -----------------------------------------------------------------
            # PASO 1: Feature Engineering en Tiempo Real
            # -----------------------------------------------------------------
            # Usamos el wrapper para generar lags (t-1, t-5) y diffs.
            # Esto garantiza que la transformaci√≥n sea ID√âNTICA a la del entrenamiento.
            df_features = self.model_wrapper._create_lag_features(df_recent_history, target_col)
            
            # Nos interesa predecir SOLO para el √∫ltimo instante de tiempo (el "ahora")
            last_row = df_features.iloc[[-1]].copy()
            
            # -----------------------------------------------------------------
            # PASO 2: Alineaci√≥n de Columnas (Schema Matching)
            # -----------------------------------------------------------------
            # El modelo espera un orden y n√∫mero exacto de columnas.
            # Si en producci√≥n falta un sensor, debemos rellenarlo para no romper el modelo.
            expected_features = self.model_wrapper.feature_names
            
            X_input = pd.DataFrame(index=last_row.index)
            
            for feature in expected_features:
                if feature in last_row.columns:
                    X_input[feature] = last_row[feature]
                else:
                    # Fallback de seguridad: 0.0 si falta una columna calculada
                    # (Esto no deber√≠a pasar si el historial es suficiente)
                    logger.warning(f"‚ö†Ô∏è Feature faltante: {feature}. Imputando con 0.0")
                    X_input[feature] = 0.0
            
            # -----------------------------------------------------------------
            # PASO 3: Predicci√≥n y Desescalado
            # -----------------------------------------------------------------
            # Transformamos a la escala que conoce el modelo (Standard/Robust)
            X_values = X_input.values
            X_scaled = self.model_wrapper.scaler_X.transform(X_values)
            
            # Ejecutar predicci√≥n seg√∫n el tipo de modelo cargado (GP o GBR)
            confidence_interval = 0.0
            
            if self.model_wrapper.model_type == "GP":
                # Gaussian Process devuelve valor + desviaci√≥n est√°ndar (incertidumbre)
                y_pred_sc, y_std_sc = self.model_wrapper.model.predict(X_scaled, return_std=True)
                confidence_interval = float(y_std_sc[0]) 
            else:
                # Gradient Boosting / Random Forest solo devuelve valor
                y_pred_sc = self.model_wrapper.model.predict(X_scaled)
            
            # Inversi√≥n del escalado para obtener unidades reales (ej. % de recuperaci√≥n)
            y_pred_final = self.model_wrapper.scaler_y.inverse_transform(y_pred_sc.reshape(-1, 1)).ravel()[0]
            
            # -----------------------------------------------------------------
            # PASO 4: Construcci√≥n de Respuesta
            # -----------------------------------------------------------------
            # Si el dataframe de entrada ten√≠a el target, lo devolvemos para comparar
            real_value = last_row[target_col].values[0] if target_col in last_row else None
            
            return {
                "timestamp": str(last_row.index[0]),
                "predicted_value": float(y_pred_final),
                "real_value": float(real_value) if real_value else None,
                "model_used": self.model_wrapper.model_type,
                "confidence_std": confidence_interval
            }

        except Exception as e:
            logger.error(f"‚ùå Fallo durante la inferencia: {e}")
            raise