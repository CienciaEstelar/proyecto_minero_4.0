"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MÃ³dulo: core/models/mining_gp_pro.py
Proyecto: Arquitectura Minera 4.0
Autor: Juan Galaz
VersiÃ³n: 4.1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DESCRIPCIÃ“N:
    Soft-Sensor industrial para predicciÃ³n en tiempo real de variables de
    proceso en plantas de flotaciÃ³n minera. Utiliza Gaussian Process (GP)
    con optimizaciÃ³n bayesiana de hiperparÃ¡metros vÃ­a Optuna.

CARACTERÃSTICAS PRINCIPALES:
    â€¢ DiagnÃ³stico automÃ¡tico de autocorrelaciÃ³n temporal
    â€¢ Feature engineering: lags, diferencias, promedios mÃ³viles
    â€¢ EliminaciÃ³n automÃ¡tica de features constantes y correlacionados
    â€¢ Fallback inteligente a GradientBoosting si GP falla (RÂ² < 0.6)
    â€¢ CuantificaciÃ³n de incertidumbre (intervalos de confianza)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HISTORIAL DE CAMBIOS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    [v4.1.0 - Enero 2026] CLEAN CODE UPDATE
    ----------------------------------------
    
    âœ… FIX #1: Eliminado hardcode de "_iron_concentrate"
       
       ANTES (LÃ­nea ~177):
           drop_cols = [self.target_col, "_iron_concentrate"]  # âŒ Hardcode feo
       
       AHORA:
           drop_cols = [self.target_col]  # âœ… Solo el target, sistema universal
       
       RAZÃ“N: El cÃ³digo estaba pensado para un dataset especÃ­fico (hierro).
              Al querer usar el sistema con oro o cobre, fallaba porque
              "_iron_concentrate" no existÃ­a. Ahora el sistema de 
              remove_correlated_features se encarga de eliminar columnas
              redundantes automÃ¡ticamente.
    
    âœ… FIX #2: Subsample centralizado en CONFIG
       
       ANTES:
           def __init__(self, ..., subsample_step: int = 50, ...):  # âŒ Hardcode
       
       AHORA:
           def __init__(self, ..., subsample_step: int = None, ...):
               self.subsample_step = subsample_step or CONFIG.DEFAULT_SUBSAMPLE_STEP  # âœ…
       
       RAZÃ“N: El valor de subsample estaba definido diferente en cada archivo
              (10 en train, 50 en inference). Esto causaba desalineaciÃ³n de
              features. Ahora todos usan el mismo valor desde config/settings.py

    [v4.0.0] VersiÃ³n con fallback a GradientBoosting
    [v3.0.0] VersiÃ³n con optimizaciÃ³n Optuna
    [v2.0.0] VersiÃ³n con diagnÃ³stico de autocorrelaciÃ³n
    [v1.0.0] VersiÃ³n inicial bÃ¡sica

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USO BÃSICO:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    from core.models.mining_gp_pro import MiningGP
    
    # Entrenamiento completo desde archivo
    model = MiningGP(target_col="_silica_concentrate")
    metrics = model.train_from_file("data/processed/mining_clean.csv")
    
    # PredicciÃ³n
    y_pred, y_std = model.predict(X_new)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTACIONES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import sys
import json
import joblib
import optuna
import logging
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
from typing import Dict, Tuple, Optional, List, Union
from dataclasses import dataclass, field

# Sklearn - Machine Learning
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.ensemble import GradientBoostingRegressor

# Rich - Interfaz de usuario bonita
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

# ConfiguraciÃ³n centralizada del proyecto
from config.settings import CONFIG

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N DEL MÃ“DULO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
logger = logging.getLogger(__name__)

# Silenciar warnings molestos de sklearn y numpy
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)

# Estilo de grÃ¡ficos matplotlib
try:
    plt.style.use('seaborn-v0_8-whitegrid')
except:
    plt.style.use('ggplot')  # Fallback para versiones antiguas


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATACLASSES DE SOPORTE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class ModelMetrics:
    """
    Contenedor de mÃ©tricas de evaluaciÃ³n del modelo.
    
    Attributes:
        r2: Coeficiente de determinaciÃ³n (1.0 = perfecto)
        rmse: Error cuadrÃ¡tico medio (menor = mejor)
        mae: Error absoluto medio
        mape: Error porcentual absoluto medio
    """
    r2: float = 0.0
    rmse: float = 0.0
    mae: float = 0.0
    mape: float = 0.0
    
    def to_dict(self) -> dict:
        """Convierte las mÃ©tricas a diccionario (Ãºtil para JSON)."""
        return {"r2": self.r2, "rmse": self.rmse, "mae": self.mae, "mape": self.mape}
    
    def __repr__(self) -> str:
        return f"RÂ²={self.r2:.4f}, RMSE={self.rmse:.4f}, MAE={self.mae:.4f}"


@dataclass
class TrainingArtifacts:
    """
    Artefactos generados durante el entrenamiento.
    Este objeto se serializa con joblib para persistencia.
    
    Attributes:
        model: El modelo entrenado (GP o GradientBoosting)
        scaler_X: Escalador de features (RobustScaler)
        scaler_y: Escalador del target
        feature_names: Lista de nombres de features usados
        target_column: Nombre de la columna objetivo
        best_params: HiperparÃ¡metros Ã³ptimos encontrados
        metrics: MÃ©tricas de evaluaciÃ³n
        model_type: "GP" o "GradientBoosting"
        removed_features: Features eliminados durante limpieza
        training_date: Fecha/hora del entrenamiento
    """
    model: any
    scaler_X: RobustScaler
    scaler_y: RobustScaler
    feature_names: List[str]
    target_column: str
    best_params: Dict
    metrics: ModelMetrics
    model_type: str = "GP"
    removed_features: List[str] = field(default_factory=list)
    training_date: str = field(default_factory=lambda: datetime.now().isoformat())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASE PRINCIPAL: MiningGP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MiningGP:
    """
    Soft-Sensor v4.1 - VersiÃ³n Universal y Limpia.
    
    Esta clase implementa un sensor virtual (soft-sensor) para predecir
    variables de proceso minero en tiempo real, eliminando la necesidad
    de anÃ¡lisis de laboratorio que tardan horas.
    
    Cambios importantes en v4.1.0:
    -----------------------------
    1. Ya no tiene hardcode de columnas especÃ­ficas como "_iron_concentrate"
    2. El subsample_step ahora viene de CONFIG.DEFAULT_SUBSAMPLE_STEP
    3. El sistema es verdaderamente "universal" para cualquier dataset minero
    
    Example:
        >>> model = MiningGP(target_col="rougher.output.recovery")
        >>> metrics = model.train_from_file("gold_data.csv", n_trials=30)
        >>> print(f"RÂ² = {metrics.r2:.4f}")
    """
    
    def __init__(
        self, 
        target_col: str = None, 
        random_state: int = 42,
        subsample_step: int = None,  # â† [v4.1.0] Si es None, usa CONFIG
        add_lag_features: bool = True,
        lag_periods: List[int] = None,
        add_diff_features: bool = True,
        use_fallback_model: bool = True,
        remove_constant_features: bool = True,
        remove_correlated_features: bool = True,
        correlation_threshold: float = 0.98
    ):
        """
        Inicializa el Soft-Sensor.
        
        Args:
            target_col: Columna objetivo a predecir. Si es None, usa CONFIG.GP_TARGET_COLUMN
            random_state: Semilla para reproducibilidad
            subsample_step: Cada cuÃ¡ntas filas tomar una muestra.
                           [v4.1.0] Si es None, usa CONFIG.DEFAULT_SUBSAMPLE_STEP
            add_lag_features: Si True, agrega features de lag temporal
            lag_periods: Lista de periodos de lag [1, 5, 10, 20] por defecto
            add_diff_features: Si True, agrega diferencias y promedios mÃ³viles
            use_fallback_model: Si True, usa GradientBoosting cuando GP falla
            remove_constant_features: Si True, elimina features con std â‰ˆ 0
            remove_correlated_features: Si True, elimina features muy correlacionados
            correlation_threshold: Umbral de correlaciÃ³n para eliminaciÃ³n (0.98 default)
        """
        # Interfaz de usuario
        self.console = Console()
        
        # Columna objetivo: usar la del argumento o la de CONFIG
        self.target_col = target_col or CONFIG.GP_TARGET_COLUMN
        self.random_state = random_state
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [v4.1.0] FIX: Subsample centralizado
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ANTES: subsample_step: int = 50  (hardcodeado)
        # AHORA: Si no se especifica, usa el valor de CONFIG
        # Esto garantiza consistencia entre entrenamiento e inferencia
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if subsample_step is not None:
            self.subsample_step = subsample_step
        else:
            self.subsample_step = CONFIG.DEFAULT_SUBSAMPLE_STEP
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # ConfiguraciÃ³n de feature engineering
        self.add_lag_features = add_lag_features
        self.lag_periods = lag_periods or [1, 5, 10, 20]
        self.add_diff_features = add_diff_features
        
        # ConfiguraciÃ³n de comportamiento
        self.use_fallback_model = use_fallback_model
        self.remove_constant_features = remove_constant_features
        self.remove_correlated_features = remove_correlated_features
        self.correlation_threshold = correlation_threshold
        
        # Escaladores (se ajustan durante fit)
        self.scaler_X = RobustScaler()
        self.scaler_y = RobustScaler()
        
        # Estado interno
        self.model = None
        self.model_type = "GP"  # Puede cambiar a "GradientBoosting"
        self.feature_names: List[str] = []
        self.removed_features: List[str] = []
        self.best_params: Dict = {}
        self.metrics: Optional[ModelMetrics] = None
        self.data_diagnosis: Dict = {}
        
        # Log de inicializaciÃ³n
        logger.info(
            f"MiningGP v4.1.0 inicializado - "
            f"Target: {self.target_col}, "
            f"Subsample: {self.subsample_step} (desde CONFIG)"
        )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODOS DE DIAGNÃ“STICO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _diagnose_data(self, y_series: pd.Series) -> Dict:
        """
        DiagnÃ³stico automÃ¡tico de la serie temporal objetivo.
        
        Analiza la autocorrelaciÃ³n para determinar quÃ© tan "pegados" estÃ¡n
        los datos consecutivos. Alta autocorrelaciÃ³n = datos redundantes.
        
        Args:
            y_series: Serie temporal del target
            
        Returns:
            Dict con estadÃ­sticas y recomendaciones
        """
        diagnosis = {
            "n_samples": len(y_series),
            "mean": y_series.mean(),
            "std": y_series.std(),
            "cv": (y_series.std() / y_series.mean()) * 100 if y_series.mean() != 0 else 0,
            "autocorr_1": y_series.autocorr(lag=1),
            "autocorr_10": y_series.autocorr(lag=10) if len(y_series) > 10 else 0,
            "autocorr_50": y_series.autocorr(lag=50) if len(y_series) > 50 else 0,
        }
        
        # Encontrar el subsample recomendado (donde autocorr < 0.85)
        for lag in [10, 20, 30, 40, 50, 75, 100, 150, 200]:
            if len(y_series) > lag:
                ac = y_series.autocorr(lag=lag)
                if ac < 0.85:
                    diagnosis["recommended_subsample"] = lag
                    break
        else:
            diagnosis["recommended_subsample"] = 200
        
        # Clasificar severidad del problema de autocorrelaciÃ³n
        if diagnosis["autocorr_1"] > 0.98:
            diagnosis["severity"] = "CRÃTICA"
        elif diagnosis["autocorr_1"] > 0.95:
            diagnosis["severity"] = "ALTA"
        elif diagnosis["autocorr_1"] > 0.90:
            diagnosis["severity"] = "MODERADA"
        else:
            diagnosis["severity"] = "OK"
        
        return diagnosis
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODOS DE PREPROCESAMIENTO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _remove_problematic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Elimina features problemÃ¡ticos automÃ¡ticamente.
        
        Criterios de eliminaciÃ³n:
        1. Features constantes (std < 1e-8): No aportan informaciÃ³n
        2. Features altamente correlacionados (r > threshold): Redundantes
        
        Args:
            df: DataFrame con features (sin el target)
            
        Returns:
            DataFrame limpio sin features problemÃ¡ticos
        """
        df = df.copy()
        removed = []
        
        # --- Paso 1: Eliminar features constantes ---
        if self.remove_constant_features:
            for col in df.columns:
                if df[col].std() < 1e-8:
                    removed.append(f"{col} (constante)")
                    df = df.drop(columns=[col])
        
        # --- Paso 2: Eliminar features muy correlacionados ---
        if self.remove_correlated_features and len(df.columns) > 1:
            # Matriz de correlaciÃ³n absoluta
            corr_matrix = df.corr().abs()
            # TriÃ¡ngulo superior (para no duplicar comparaciones)
            upper = corr_matrix.where(
                np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
            )
            
            # Encontrar columnas con correlaciÃ³n > threshold
            to_drop = []
            for col in upper.columns:
                high_corr = upper.index[upper[col] > self.correlation_threshold].tolist()
                if high_corr:
                    to_drop.extend(high_corr)
            
            # Eliminar duplicados y dropear
            to_drop = list(set(to_drop))
            for col in to_drop:
                if col in df.columns:
                    removed.append(f"{col} (correlaciÃ³n > {self.correlation_threshold})")
                    df = df.drop(columns=[col])
        
        # --- Log de features eliminados ---
        if removed:
            self.console.print(f"[yellow]   âš ï¸  Features eliminados automÃ¡ticamente:[/yellow]")
            for r in removed[:5]:  # Mostrar mÃ¡ximo 5
                self.console.print(f"[dim]      - {r}[/dim]")
            if len(removed) > 5:
                self.console.print(f"[dim]      ... y {len(removed)-5} mÃ¡s[/dim]")
        
        self.removed_features = removed
        return df
    
    def _create_lag_features(self, df: pd.DataFrame, y_col: str) -> pd.DataFrame:
        """
        Crea features de ingenierÃ­a temporal.
        
        El Gaussian Process necesita contexto temporal para entender
        la dinÃ¡mica del proceso. Agregamos:
        - Lags: valor de Y en t-1, t-5, t-10, t-20
        - Diferencias: cambio de Y entre t y t-1
        - Promedios mÃ³viles: suavizado de Y
        
        Args:
            df: DataFrame con datos
            y_col: Nombre de la columna objetivo
            
        Returns:
            DataFrame con features adicionales
        """
        df = df.copy()
        y = df[y_col]
        
        # --- Features de Lag ---
        if self.add_lag_features:
            for lag in self.lag_periods:
                df[f'{y_col}_lag_{lag}'] = y.shift(lag)
        
        # --- Features de Diferencia y Tendencia ---
        if self.add_diff_features:
            df[f'{y_col}_diff_1'] = y.diff(1)           # Cambio instantÃ¡neo
            df[f'{y_col}_diff_5'] = y.diff(5)           # Cambio en 5 periodos
            df[f'{y_col}_rolling_mean_10'] = y.rolling(10, min_periods=1).mean()
            df[f'{y_col}_rolling_std_10'] = y.rolling(10, min_periods=1).std()
        
        return df
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODO PRINCIPAL: CARGA DE DATOS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def load_data(
        self, 
        filepath: str = None,
        max_rows: int = 100000
    ) -> Tuple[np.ndarray, np.ndarray, pd.DatetimeIndex]:
        """
        Carga y preprocesa datos desde un archivo CSV.
        
        Pipeline completo:
        1. Leer CSV con lÃ­mite de filas
        2. DiagnÃ³stico de autocorrelaciÃ³n
        3. Subsampleo temporal (reduce autocorrelaciÃ³n)
        4. Feature engineering (lags, diferencias)
        5. Limpieza de features problemÃ¡ticos
        6. Escalado robusto
        
        Args:
            filepath: Ruta al CSV. Si None, usa CONFIG.DATA_CLEAN_PATH
            max_rows: MÃ¡ximo de filas a cargar (las Ãºltimas)
            
        Returns:
            Tuple de (X_scaled, y_scaled, dates_index)
        """
        filepath = filepath or str(CONFIG.DATA_CLEAN_PATH)
        
        self.console.print(f"[bold cyan]ğŸ“¥ Cargando datos desde:[/bold cyan] {filepath}")
        
        # Verificar existencia del archivo
        if not Path(filepath).exists():
            raise FileNotFoundError(f"No encontrado: {filepath}")
        
        # Contar filas totales (para skip inteligente)
        with open(filepath, 'r') as f:
            total_rows = sum(1 for _ in f) - 1  # -1 por header
        
        skip_rows = max(0, total_rows - max_rows)
        self.console.print(f"[dim]   Archivo: {total_rows:,} filas totales[/dim]")
        
        # Leer CSV
        df = pd.read_csv(
            filepath, 
            index_col=0,
            parse_dates=True,
            skiprows=range(1, skip_rows + 1) if skip_rows > 0 else None
        )
        
        # Validar que existe el target
        if self.target_col not in df.columns:
            raise ValueError(
                f"Target '{self.target_col}' no encontrado en el dataset.\n"
                f"Columnas disponibles: {list(df.columns[:10])}..."
            )
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # DIAGNÃ“STICO DE AUTOCORRELACIÃ“N
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.console.print(f"\n[bold yellow]ğŸ”¬ DiagnÃ³stico de AutocorrelaciÃ³n:[/bold yellow]")
        self.data_diagnosis = self._diagnose_data(df[self.target_col])
        
        # Mostrar diagnÃ³stico en tabla bonita
        diag_table = Table(show_header=False, box=None, padding=(0, 2))
        diag_table.add_row("Autocorr lag-1:", f"{self.data_diagnosis['autocorr_1']:.4f}")
        diag_table.add_row("Autocorr lag-50:", f"{self.data_diagnosis['autocorr_50']:.4f}")
        
        sev = self.data_diagnosis['severity']
        sev_color = "red" if sev == "CRÃTICA" else "yellow" if sev in ["ALTA", "MODERADA"] else "green"
        diag_table.add_row("Severidad:", f"[{sev_color}]{sev}[/{sev_color}]")
        diag_table.add_row("Subsample recomendado:", f"cada {self.data_diagnosis['recommended_subsample']}")
        self.console.print(diag_table)
        
        # Auto-ajustar subsample si la autocorrelaciÃ³n es crÃ­tica
        if self.data_diagnosis["autocorr_1"] > 0.98:
            recommended = self.data_diagnosis["recommended_subsample"]
            if self.subsample_step < recommended:
                self.console.print(
                    f"[yellow]   âš ï¸  Auto-ajustando subsample: "
                    f"{self.subsample_step} â†’ {recommended}[/yellow]"
                )
                self.subsample_step = recommended
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SUBSAMPLEO TEMPORAL
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.subsample_step > 1:
            df = df.iloc[::self.subsample_step]
            self.console.print(
                f"[dim]   Subsampleado 1/{self.subsample_step}: {len(df):,} filas[/dim]"
            )
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FEATURE ENGINEERING
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        df = self._create_lag_features(df, self.target_col)
        df = df.dropna()  # Los lags crean NaNs al inicio
        self.console.print(
            f"[dim]   Con feature engineering: {len(df):,} filas, {len(df.columns)} columnas[/dim]"
        )
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SEPARAR X e Y
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        y_series = df[self.target_col]
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [v4.1.0] FIX: Eliminado hardcode de "_iron_concentrate"
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ANTES:
        #   drop_cols = [self.target_col, "_iron_concentrate"]  # âŒ Hardcode
        #
        # AHORA:
        #   Solo eliminamos el target. El sistema de remove_correlated_features
        #   se encargarÃ¡ de eliminar columnas redundantes automÃ¡ticamente.
        #   Esto hace que el cÃ³digo sea verdaderamente "universal" y funcione
        #   con cualquier dataset minero (hierro, oro, cobre, etc.)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        drop_cols = [self.target_col]  # âœ… Solo el target, nada hardcodeado
        X_df = df.drop(columns=[c for c in drop_cols if c in df.columns])
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Eliminar features problemÃ¡ticos (constantes, correlacionados)
        X_df = self._remove_problematic_features(X_df)
        
        # Guardar nombres de features para inferencia
        self.feature_names = X_df.columns.tolist()
        
        # Convertir a numpy arrays
        X = X_df.values
        y = y_series.values.reshape(-1, 1)
        
        # Escalar (RobustScaler es resistente a outliers)
        X_scaled = self.scaler_X.fit_transform(X)
        y_scaled = self.scaler_y.fit_transform(y)
        
        # Mostrar estadÃ­sticas finales
        new_autocorr = y_series.autocorr(lag=1) if len(y_series) > 1 else 0
        self.console.print(
            f"\n[green]âœ… Datos listos: {X.shape[0]:,} filas, {X.shape[1]} features[/green]"
        )
        self.console.print(f"[dim]   Nueva autocorr lag-1: {new_autocorr:.4f}[/dim]")
        
        if new_autocorr > 0.9:
            self.console.print(
                f"[yellow]   âš ï¸  AutocorrelaciÃ³n aÃºn alta. "
                f"Considerar aumentar subsample.[/yellow]"
            )
        
        return X_scaled, y_scaled, df.index
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODOS DE ENTRENAMIENTO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _train_gp(
        self, 
        X_train: np.ndarray, 
        y_train: np.ndarray, 
        n_trials: int
    ) -> Tuple[any, Dict, float]:
        """
        Entrena Gaussian Process con optimizaciÃ³n bayesiana de hiperparÃ¡metros.
        
        Usa Optuna para encontrar los mejores valores de:
        - alpha: ruido de regularizaciÃ³n
        - length_scale: escala del kernel Matern
        - nu: suavidad del kernel (1.5 o 2.5)
        - noise_level: ruido del kernel WhiteKernel
        
        Args:
            X_train: Features de entrenamiento (escalados)
            y_train: Target de entrenamiento (escalado)
            n_trials: NÃºmero de trials de optimizaciÃ³n
            
        Returns:
            Tuple de (modelo_sin_entrenar, mejores_params, score_cv)
        """
        
        def objective(trial):
            """FunciÃ³n objetivo para Optuna."""
            # Sugerir hiperparÃ¡metros
            alpha = trial.suggest_float("alpha", 1e-4, 1e-1, log=True)
            length_scale = trial.suggest_float("length_scale", 1.0, 25.0, log=True)
            nu = trial.suggest_categorical("nu", [1.5, 2.5])
            noise = trial.suggest_float("noise_level", 0.001, 0.1, log=True)
            
            # Construir kernel compuesto
            kernel = (
                ConstantKernel(1.0, (1e-3, 1e3)) *
                Matern(length_scale=length_scale, nu=nu, length_scale_bounds=(0.01, 100)) +
                WhiteKernel(noise_level=noise, noise_level_bounds=(0.01, 10))
            )
            
            # Crear modelo
            model = GaussianProcessRegressor(
                kernel=kernel, 
                alpha=alpha,
                random_state=self.random_state,
                n_restarts_optimizer=2
            )
            
            # Subsamplear para velocidad en optimizaciÃ³n
            max_samples = min(600, len(X_train))
            step = max(1, len(X_train) // max_samples)
            X_opt = X_train[::step][:max_samples]
            y_opt = y_train[::step][:max_samples]
            
            # Cross-validation temporal (respeta orden cronolÃ³gico)
            tscv = TimeSeriesSplit(n_splits=3)
            scores = []
            
            for train_idx, test_idx in tscv.split(X_opt):
                try:
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        model.fit(X_opt[train_idx], y_opt[train_idx].ravel())
                    pred = model.predict(X_opt[test_idx])
                    score = r2_score(y_opt[test_idx], pred)
                    scores.append(max(score, -1.0))  # Clamp negatives
                except:
                    return -1.0
            
            return np.mean(scores)
        
        # Ejecutar optimizaciÃ³n
        optuna.logging.set_verbosity(optuna.logging.WARNING)
        study = optuna.create_study(direction="maximize")
        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)
        
        best_params = study.best_params
        best_score = study.best_value
        
        # Reconstruir el mejor modelo
        kernel = (
            ConstantKernel(1.0, (1e-3, 1e3)) *
            Matern(
                length_scale=best_params["length_scale"], 
                nu=best_params["nu"],
                length_scale_bounds=(0.01, 100)
            ) +
            WhiteKernel(
                noise_level=best_params["noise_level"],
                noise_level_bounds=(0.01, 10)
            )
        )
        
        model = GaussianProcessRegressor(
            kernel=kernel,
            alpha=best_params["alpha"],
            n_restarts_optimizer=3,
            random_state=self.random_state
        )
        
        return model, best_params, best_score
    
    def _train_fallback(
        self, 
        X_train: np.ndarray, 
        y_train: np.ndarray
    ) -> Tuple[any, Dict]:
        """
        Modelo alternativo: GradientBoosting.
        
        Se usa cuando el GP no logra RÂ² > 0.6, lo cual indica que
        el problema probablemente no es suave/estacionario.
        
        Args:
            X_train: Features de entrenamiento
            y_train: Target de entrenamiento
            
        Returns:
            Tuple de (modelo_sin_entrenar, params)
        """
        self.console.print(
            "[yellow]ğŸ”„ Gaussian Process fallÃ³. "
            "Usando GradientBoosting como alternativa...[/yellow]"
        )
        
        model = GradientBoostingRegressor(
            n_estimators=150,
            max_depth=4,
            learning_rate=0.1,
            subsample=0.8,
            min_samples_leaf=10,
            random_state=self.random_state
        )
        
        params = {
            "model": "GradientBoosting", 
            "n_estimators": 150, 
            "max_depth": 4
        }
        
        return model, params
    
    def optimize_and_train(
        self, 
        X: np.ndarray, 
        y: np.ndarray, 
        n_trials: int = None
    ) -> None:
        """
        Optimiza hiperparÃ¡metros y entrena el modelo final.
        
        Pipeline:
        1. Optimizar GP con Optuna
        2. Evaluar CV score
        3. Si CV < 0.6, cambiar a GradientBoosting
        4. Entrenar modelo final con todos los datos
        
        Args:
            X: Features escalados
            y: Target escalado
            n_trials: NÃºmero de trials Optuna (usa CONFIG si es None)
        """
        n_trials = n_trials or CONFIG.GP_OPTUNA_TRIALS
        max_samples = CONFIG.GP_MAX_TRAIN_SAMPLES
        
        self.console.print(
            f"\n[bold yellow]âš¡ Optimizando Gaussian Process "
            f"({n_trials} trials)...[/bold yellow]"
        )
        
        # Fase 1: OptimizaciÃ³n
        model, params, cv_score = self._train_gp(X, y, n_trials)
        
        self.console.print(f"\n[bold]CV Score: RÂ² = {cv_score:.4f}[/bold]")
        
        # Fase 2: Decidir modelo final
        if cv_score < 0.60 and self.use_fallback_model:
            self.console.print(
                f"[red]âŒ GP no alcanzÃ³ RÂ² > 0.6. Cambiando a modelo alternativo.[/red]"
            )
            model, params = self._train_fallback(X, y)
            self.model_type = "GradientBoosting"
        else:
            self.model_type = "GP"
        
        self.best_params = params
        
        # Mostrar parÃ¡metros
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("ParÃ¡metro")
        table.add_column("Valor")
        for k, v in params.items():
            val_str = f"{v:.6g}" if isinstance(v, float) else str(v)
            table.add_row(k, val_str)
        self.console.print(table)
        
        # Fase 3: Entrenar con datos limitados (GP es O(nÂ³))
        if len(X) > max_samples:
            step = max(1, len(X) // max_samples)
            indices = np.arange(0, len(X), step)[:max_samples]
            X_train, y_train = X[indices], y[indices]
            self.console.print(
                f"[dim]Entrenando con {len(X_train):,} de {len(X):,} muestras "
                f"(lÃ­mite de memoria)[/dim]"
            )
        else:
            X_train, y_train = X, y
        
        self.console.print(f"[bold blue]ğŸš€ Entrenando {self.model_type}...[/bold blue]")
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            model.fit(X_train, y_train.ravel())
        
        self.model = model
        self.console.print(f"[green]âœ… {self.model_type} entrenado exitosamente[/green]")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODOS DE PREDICCIÃ“N Y EVALUACIÃ“N
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def predict(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Genera predicciones con incertidumbre.
        
        Args:
            X: Features escalados
            
        Returns:
            Tuple de (predicciones, desviaciones_estÃ¡ndar) en escala original
        """
        if self.model is None:
            raise ValueError("Modelo no entrenado. Ejecuta train_from_file() primero.")
        
        # Predecir (GP devuelve incertidumbre, GradientBoosting no)
        if self.model_type == "GP":
            y_pred_scaled, y_std_scaled = self.model.predict(X, return_std=True)
        else:
            y_pred_scaled = self.model.predict(X)
            y_std_scaled = np.zeros_like(y_pred_scaled)
        
        # Desescalar predicciones
        y_pred = self.scaler_y.inverse_transform(
            y_pred_scaled.reshape(-1, 1)
        ).ravel()
        
        # Desescalar incertidumbre
        if hasattr(self.scaler_y, 'scale_') and self.scaler_y.scale_ is not None:
            y_std = y_std_scaled * self.scaler_y.scale_[0]
        else:
            y_std = y_std_scaled
        
        return y_pred, y_std
    
    def evaluate(self, y_true: np.ndarray, y_pred: np.ndarray) -> ModelMetrics:
        """
        Calcula mÃ©tricas de evaluaciÃ³n.
        
        Args:
            y_true: Valores reales
            y_pred: Valores predichos
            
        Returns:
            ModelMetrics con RÂ², RMSE, MAE, MAPE
        """
        # MAPE solo donde y_true != 0 para evitar divisiÃ³n por cero
        mask = y_true != 0
        if mask.any():
            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
        else:
            mape = 0.0
        
        self.metrics = ModelMetrics(
            r2=r2_score(y_true, y_pred),
            rmse=np.sqrt(mean_squared_error(y_true, y_pred)),
            mae=mean_absolute_error(y_true, y_pred),
            mape=mape
        )
        
        return self.metrics
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODOS DE PERSISTENCIA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def save(self, filepath: str = None) -> str:
        """
        Guarda el modelo y artefactos a disco.
        
        Args:
            filepath: Ruta destino. Si None, genera nombre automÃ¡tico.
            
        Returns:
            Ruta del archivo guardado
        """
        if self.model is None:
            raise ValueError("No hay modelo para guardar")
        
        # Generar nombre si no se especifica
        if filepath is None:
            CONFIG.MODELS_DIR.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = str(
                CONFIG.MODELS_DIR / 
                f"{self.model_type.lower()}_{self.target_col}_{timestamp}.pkl"
            )
        
        # Empaquetar artefactos
        artifacts = TrainingArtifacts(
            model=self.model,
            scaler_X=self.scaler_X,
            scaler_y=self.scaler_y,
            feature_names=self.feature_names,
            target_column=self.target_col,
            best_params=self.best_params,
            metrics=self.metrics,
            model_type=self.model_type,
            removed_features=self.removed_features
        )
        
        joblib.dump(artifacts, filepath)
        self.console.print(f"[green]ğŸ’¾ Modelo guardado: {filepath}[/green]")
        
        return filepath
    
    def load(self, filepath: str) -> None:
        """
        Carga modelo y artefactos desde disco.
        
        Args:
            filepath: Ruta al archivo .pkl
        """
        artifacts: TrainingArtifacts = joblib.load(filepath)
        
        self.model = artifacts.model
        self.scaler_X = artifacts.scaler_X
        self.scaler_y = artifacts.scaler_y
        self.feature_names = artifacts.feature_names
        self.target_col = artifacts.target_column
        self.best_params = artifacts.best_params
        self.metrics = artifacts.metrics
        self.model_type = getattr(artifacts, 'model_type', 'GP')
        self.removed_features = getattr(artifacts, 'removed_features', [])
        
        self.console.print(
            f"[green]ğŸ“‚ Modelo cargado: {filepath} ({self.model_type})[/green]"
        )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODOS DE VISUALIZACIÃ“N
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def generate_report(
        self, 
        y_true, 
        y_pred, 
        y_std, 
        dates, 
        output_dir=None
    ) -> List[str]:
        """
        Genera grÃ¡ficos de diagnÃ³stico del modelo.
        
        Crea un panel con 4 grÃ¡ficos:
        1. Serie temporal: predicciÃ³n vs real
        2. Scatter plot: correlaciÃ³n predicho vs real
        3. Histograma de errores
        4. Residuos vs predicciÃ³n
        
        Args:
            y_true: Valores reales
            y_pred: Valores predichos
            y_std: DesviaciÃ³n estÃ¡ndar de predicciones
            dates: Ãndice temporal
            output_dir: Directorio de salida
            
        Returns:
            Lista de rutas de archivos generados
        """
        output_dir = Path(output_dir or CONFIG.RESULTS_DIR)
        output_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # --- GrÃ¡fico 1: Serie Temporal ---
        n = min(200, len(y_true))  # Ãšltimas 200 observaciones
        axes[0, 0].plot(dates[-n:], y_true[-n:], 'k-', lw=1, alpha=0.8, label='Real')
        axes[0, 0].plot(dates[-n:], y_pred[-n:], 'r--', lw=1.5, label='PredicciÃ³n')
        
        # Banda de confianza 95%
        if np.any(y_std > 0):
            axes[0, 0].fill_between(
                dates[-n:], 
                y_pred[-n:] - 1.96 * y_std[-n:],
                y_pred[-n:] + 1.96 * y_std[-n:], 
                color='red', alpha=0.15, label='IC 95%'
            )
        
        axes[0, 0].set_title(f'Serie Temporal ({self.model_type})')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # --- GrÃ¡fico 2: Scatter Plot ---
        axes[0, 1].scatter(y_true, y_pred, alpha=0.4, s=10, c='steelblue')
        lims = [min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]
        axes[0, 1].plot(lims, lims, 'k--', lw=2, label='LÃ­nea perfecta')
        axes[0, 1].set_title(f'RÂ² = {self.metrics.r2:.4f}')
        axes[0, 1].set_xlabel('Valor Real')
        axes[0, 1].set_ylabel('Valor Predicho')
        axes[0, 1].legend()
        
        # --- GrÃ¡fico 3: Histograma de Errores ---
        errors = y_true - y_pred
        axes[1, 0].hist(errors, bins=50, color='steelblue', edgecolor='white', alpha=0.8)
        axes[1, 0].axvline(0, color='red', ls='--', lw=2, label='Error = 0')
        axes[1, 0].set_title('DistribuciÃ³n de Errores')
        axes[1, 0].set_xlabel('Error (Real - Predicho)')
        axes[1, 0].legend()
        
        # --- GrÃ¡fico 4: Residuos vs PredicciÃ³n ---
        axes[1, 1].scatter(y_pred, errors, alpha=0.3, s=10, c='steelblue')
        axes[1, 1].axhline(0, color='red', ls='--', lw=2)
        axes[1, 1].set_title('Residuos vs PredicciÃ³n (detecta heterocedasticidad)')
        axes[1, 1].set_xlabel('Valor Predicho')
        axes[1, 1].set_ylabel('Residuo')
        
        plt.suptitle(
            f'{self.model_type} | Target: {self.target_col}', 
            fontsize=14, fontweight='bold'
        )
        plt.tight_layout()
        
        # Guardar figura
        path = output_dir / f"{self.model_type.lower()}_report_{timestamp}.png"
        plt.savefig(path, dpi=150, bbox_inches='tight')
        plt.close()
        
        self.console.print(f"[green]ğŸ“Š Reporte guardado: {path}[/green]")
        
        return [str(path)]
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PIPELINE COMPLETO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def train_from_file(
        self, 
        filepath=None, 
        test_size=0.2, 
        n_trials=None, 
        save_model=True
    ) -> ModelMetrics:
        """
        Pipeline completo: carga datos, entrena, evalÃºa y guarda.
        
        Este es el mÃ©todo principal para uso tÃ­pico. Ejecuta todos los
        pasos necesarios de principio a fin.
        
        Args:
            filepath: Ruta al CSV. Si None, usa CONFIG.DATA_CLEAN_PATH
            test_size: ProporciÃ³n de datos para test (default 20%)
            n_trials: NÃºmero de trials Optuna
            save_model: Si True, guarda el modelo entrenado
            
        Returns:
            ModelMetrics con los resultados de evaluaciÃ³n
        """
        # Paso 1: Cargar y preparar datos
        X, y, dates = self.load_data(filepath)
        
        # Paso 2: Split temporal (respeta orden cronolÃ³gico)
        test_idx = int(len(X) * (1 - test_size))
        X_train, X_test = X[:test_idx], X[test_idx:]
        y_train, y_test = y[:test_idx], y[test_idx:]
        dates_test = dates[test_idx:]
        
        # Paso 3: Entrenar
        self.optimize_and_train(X_train, y_train, n_trials=n_trials)
        
        # Paso 4: Evaluar en test set
        y_test_real = self.scaler_y.inverse_transform(y_test).ravel()
        y_pred, y_std = self.predict(X_test)
        metrics = self.evaluate(y_test_real, y_pred)
        
        # Mostrar resultados
        self.console.print("\n" + "=" * 50)
        self.console.print(f"[bold]ğŸ† RESULTADOS FINALES ({self.model_type})[/bold]")
        self.console.print("=" * 50)
        
        table = Table(header_style="bold green")
        table.add_column("MÃ©trica")
        table.add_column("Valor")
        table.add_column("InterpretaciÃ³n")
        
        # RÂ² con color segÃºn calidad
        r2_color = "green" if metrics.r2 > 0.7 else "yellow" if metrics.r2 > 0.5 else "red"
        r2_interp = "Excelente" if metrics.r2 > 0.8 else "Bueno" if metrics.r2 > 0.6 else "Pobre"
        table.add_row("RÂ² Score", f"[{r2_color}]{metrics.r2:.4f}[/{r2_color}]", r2_interp)
        table.add_row("RMSE", f"{metrics.rmse:.4f}", "Error tÃ­pico")
        table.add_row("MAE", f"{metrics.mae:.4f}", "Error absoluto promedio")
        table.add_row("MAPE", f"{metrics.mape:.2f}%", "Error porcentual")
        
        self.console.print(table)
        
        # Paso 5: Generar reporte visual
        self.generate_report(y_test_real, y_pred, y_std, dates_test)
        
        # Paso 6: Guardar modelo
        if save_model:
            self.save()
        
        return metrics


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXPORTS PÃšBLICOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
__all__ = ["MiningGP", "ModelMetrics", "TrainingArtifacts"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI (Command Line Interface)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """
    Punto de entrada para uso desde lÃ­nea de comandos.
    
    Ejemplos:
        python mining_gp_pro.py --data data/clean.csv --target _silica_concentrate
        python mining_gp_pro.py --trials 30 --subsample 20
    """
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Soft-Sensor GP v4.1.0 (Universal)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python mining_gp_pro.py
  python mining_gp_pro.py --data data/gold.csv --target recovery
  python mining_gp_pro.py --trials 30 --subsample 20 --no-fallback
        """
    )
    parser.add_argument("--data", "-d", type=str, default=None,
                       help="Ruta al archivo CSV (default: usa CONFIG)")
    parser.add_argument("--target", "-t", type=str, default=None,
                       help="Columna objetivo (default: usa CONFIG)")
    parser.add_argument("--trials", "-n", type=int, default=None,
                       help="NÃºmero de trials Optuna (default: 15)")
    parser.add_argument("--test-size", type=float, default=0.2,
                       help="ProporciÃ³n de test (default: 0.2)")
    parser.add_argument("--subsample", "-s", type=int, default=None,
                       help="Subsample step (default: usa CONFIG)")
    parser.add_argument("--no-lags", action="store_true",
                       help="Desactivar features de lag")
    parser.add_argument("--no-fallback", action="store_true",
                       help="No usar GradientBoosting como alternativa")
    parser.add_argument("--no-save", action="store_true",
                       help="No guardar el modelo")
    
    args = parser.parse_args()
    
    try:
        model = MiningGP(
            target_col=args.target,
            subsample_step=args.subsample,
            add_lag_features=not args.no_lags,
            use_fallback_model=not args.no_fallback
        )
        
        metrics = model.train_from_file(
            filepath=args.data,
            test_size=args.test_size,
            n_trials=args.trials,
            save_model=not args.no_save
        )
        
        # Exit code basado en calidad del modelo
        exit(0 if metrics.r2 > 0 else 1)
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    main()
